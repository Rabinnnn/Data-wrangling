{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a647435-54d6-4288-b1ff-fd7851406cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the two DataFrames\n",
    "df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
    "                   columns=['letter', 'number'])\n",
    "df2 = pd.DataFrame([['c', 1], ['d', 2]],\n",
    "                   columns=['letter', 'number'])\n",
    "\n",
    "# Concatenate the DataFrames vertically (axis=0) and reset the index\n",
    "# The default axis is 0, so we don't need to specify it.\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Print the resulting DataFrame and its index type\n",
    "print(\"Combined DataFrame:\")\n",
    "print(df_combined)\n",
    "print(\"\\nIndex Type:\")\n",
    "print(df_combined.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d874f05-fc52-443a-b263-04162ca23c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the first DataFrame (df1)\n",
    "df1_dict = {\n",
    "        'id': ['1', '2', '3', '4', '5'],\n",
    "        'Feature1': ['A', 'C', 'E', 'G', 'I'],\n",
    "        'Feature2': ['B', 'D', 'F', 'H', 'J']}\n",
    "df1 = pd.DataFrame(df1_dict, columns = ['id', 'Feature1', 'Feature2'])\n",
    "\n",
    "# Define the second DataFrame (df2)\n",
    "df2_dict = {\n",
    "        'id': ['1', '2', '6', '7', '8'],\n",
    "        'Feature1': ['K', 'M', 'O', 'Q', 'S'],\n",
    "        'Feature2': ['L', 'N', 'P', 'R', 'T']}\n",
    "df2 = pd.DataFrame(df2_dict, columns = ['id', 'Feature1', 'Feature2'])\n",
    "\n",
    "print(\"--- DataFrame 1 ---\")\n",
    "print(df1)\n",
    "print(\"\\n--- DataFrame 2 ---\")\n",
    "print(df2)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd3720-d468-450b-8d61-4b5b9f17577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner Merge: Keeps only the intersecting IDs ('1' and '2')\n",
    "df_inner = pd.merge(df1, df2, on='id', how='inner')\n",
    "\n",
    "print(\"Output 1: Inner Merge\")\n",
    "print(df_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c383777-9ffe-41e5-b8f8-41750e6b51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer Merge: Keeps all IDs from both DataFrames\n",
    "df_outer = pd.merge(\n",
    "    df1,\n",
    "    df2,\n",
    "    on='id',\n",
    "    how='outer',\n",
    "    suffixes=('_df1', '_df2') # Set custom suffixes for clarity\n",
    ")\n",
    "\n",
    "# Replace 'nan' with 'nannan' for visual match with your example (optional step)\n",
    "df_outer = df_outer.fillna('nan')\n",
    "\n",
    "print(\"\\nOutput 2: Full Outer Merge\")\n",
    "print(df_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa80930c-5d47-4c33-a4b5-85768def1ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape: (1305, 5)\n",
      "\n",
      "merged_df.head():\n",
      "|                                            |      Open |     Close |   Close_Adjusted |   Twitter |    Reddit |\n",
      "|:-------------------------------------------|----------:|----------:|-----------------:|----------:|----------:|\n",
      "| (Timestamp('2021-01-01 00:00:00'), 'AAPL') | -0.710692 |  0.683618 |        -0.734952 |  1.29918  | -0.915968 |\n",
      "| (Timestamp('2021-01-01 00:00:00'), 'FB')   | -0.90291  |  1.76793  |         0.96074  | -1.54523  |  0.803316 |\n",
      "| (Timestamp('2021-01-01 00:00:00'), 'GE')   | -1.86151  | -0.764768 |         0.242463 | -1.64624  |  1.21953  |\n",
      "| (Timestamp('2021-01-01 00:00:00'), 'AMZN') |  0.323755 | -1.49049  |         1.15857  | -0.904395 | -1.10329  |\n",
      "| (Timestamp('2021-01-01 00:00:00'), 'DAI')  |  0.825224 |  0.481902 |         1.35673  |  0.248462 | -1.03814  |\n",
      "\n",
      "Validation Check (Q2): True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# generate days\n",
    "all_dates = pd.date_range('2021-01-01', '2021-12-15')\n",
    "business_dates = pd.bdate_range('2021-01-01', '2021-12-31')\n",
    "\n",
    "# generate tickers\n",
    "tickers = ['AAPL', 'FB', 'GE', 'AMZN', 'DAI']\n",
    "\n",
    "# create indexs\n",
    "index_alt = pd.MultiIndex.from_product([all_dates, tickers], names=['Date', 'Ticker'])\n",
    "index = pd.MultiIndex.from_product([business_dates, tickers], names=['Date', 'Ticker'])\n",
    "\n",
    "# create DFs\n",
    "market_data = pd.DataFrame(index=index,\n",
    "                        data=np.random.randn(len(index), 3),\n",
    "                        columns=['Open','Close','Close_Adjusted'])\n",
    "\n",
    "alternative_data = pd.DataFrame(index=index_alt,\n",
    "                                data=np.random.randn(len(index_alt), 2),\n",
    "                                columns=['Twitter','Reddit'])\n",
    "\n",
    "# --- Question 1: Merge MultiIndex ---\n",
    "merged_df = market_data.merge(alternative_data, \n",
    "                             how='left', \n",
    "                             left_index=True, \n",
    "                             right_index=True)\n",
    "\n",
    "# --- Question 2: Fill Missing Values ---\n",
    "filled_df = merged_df.fillna(0)\n",
    "\n",
    "# Validation check:\n",
    "validation_result = filled_df.sum().sum() == merged_df.sum().sum()\n",
    "\n",
    "# Output the required validation results\n",
    "print(f\"DataFrame Shape: {merged_df.shape}\")\n",
    "print(\"\\nmerged_df.head():\")\n",
    "print(merged_df.head().to_markdown())\n",
    "print(f\"\\nValidation Check (Q2): {validation_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6719a55d-b87e-4273-99e5-e772cece350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   sequence |\n",
      "|---:|-----------:|\n",
      "|  0 |        2.8 |\n",
      "|  1 |        2.8 |\n",
      "|  2 |        3   |\n",
      "|  3 |        4   |\n",
      "|  4 |        5   |\n",
      "|  5 |        6   |\n",
      "|  6 |        7   |\n",
      "|  7 |        8   |\n",
      "|  8 |        8.2 |\n",
      "|  9 |        8.2 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def winsorize(df: pd.DataFrame, quantiles: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies Winsorization to all numerical columns in a DataFrame without a for loop.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        quantiles (list): A list containing the lower and upper quantiles (e.g., [0.20, 0.80]).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with winsorized values.\n",
    "    \"\"\"\n",
    "    if len(quantiles) != 2 or quantiles[0] >= quantiles[1]:\n",
    "        raise ValueError(\"Quantiles must be a list of two values: [lower_q, upper_q], where lower_q < upper_q.\")\n",
    "    \n",
    "    lower_q, upper_q = quantiles[0], quantiles[1]\n",
    "    df_winsorized = df.copy()\n",
    "\n",
    "    # 1. Select only the numerical columns to process\n",
    "    numeric_df = df.select_dtypes(include=np.number)\n",
    "    \n",
    "    # 2. Calculate the cut-off values (bounds) across ALL numerical data.\n",
    "    # We flatten the numerical data to a 1D array before calculating percentiles.\n",
    "    series_data = numeric_df.values.flatten()\n",
    "    \n",
    "    # Use numpy.percentile to calculate the cut-off values (requires 0-100 range)\n",
    "    lower_bound = np.percentile(series_data, lower_q * 100)\n",
    "    upper_bound = np.percentile(series_data, upper_q * 100)\n",
    "    \n",
    "    # 3. Apply the clip method to the ENTIRE numerical DataFrame at once\n",
    "    # This replaces the need for the loop.\n",
    "    clipped_data = numeric_df.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "    \n",
    "    # 4. Update the numerical columns in the copy\n",
    "    df_winsorized[numeric_df.columns] = clipped_data\n",
    "        \n",
    "    return df_winsorized\n",
    "\n",
    "# --- Verification ---\n",
    "df = pd.DataFrame(range(1,11), columns=['sequence'])\n",
    "\n",
    "# Running the function:\n",
    "print(winsorize(df, [0.20, 0.80]).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34bacddf-6efc-404b-850c-76130221d6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winsorized DataFrame (First Rows):\n",
      "|    |   sequence |\n",
      "|---:|-----------:|\n",
      "|  0 |       1.45 |\n",
      "|  1 |       2    |\n",
      "|  2 |       3    |\n",
      "|  3 |       4    |\n",
      "|  4 |       5    |\n",
      "|  5 |       6    |\n",
      "|  6 |       7    |\n",
      "|  7 |       8    |\n",
      "|  8 |       9    |\n",
      "|  9 |       9.55 |\n",
      "| 10 |      11.45 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Reuse the Winsorize Function ---\n",
    "def winsorize(df: pd.DataFrame, quantiles: list) -> pd.DataFrame:\n",
    "    # ... (Your winsorize function body remains the same) ...\n",
    "    if len(quantiles) != 2 or quantiles[0] >= quantiles[1]:\n",
    "        raise ValueError(\"Quantiles must be a list of two values: [lower_q, upper_q], where lower_q < upper_q.\")\n",
    "    \n",
    "    lower_q, upper_q = quantiles[0], quantiles[1]\n",
    "    df_winsorized = df.copy()\n",
    "\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        series = df[col]\n",
    "        lower_bound = np.percentile(series.dropna(), lower_q * 100)\n",
    "        upper_bound = np.percentile(series.dropna(), upper_q * 100)\n",
    "        df_winsorized[col] = series.clip(lower=lower_bound, upper=upper_bound)\n",
    "        \n",
    "    return df_winsorized\n",
    "\n",
    "# --- Generate the Data Set ---\n",
    "groups = np.concatenate([np.ones(10), np.ones(10)+1,  np.ones(10)+2, np.ones(10)+3, np.ones(10)+4])\n",
    "\n",
    "df = pd.DataFrame(data= zip(groups,\n",
    "                            range(1,51)),\n",
    "                columns=[\"group\", \"sequence\"])\n",
    "\n",
    "# --- Apply Groupby and Winsorize (FIXED) ---\n",
    "quantiles_to_use = [0.05, 0.95]\n",
    "\n",
    "# FIX: Add include_groups=False to silence the FutureWarning\n",
    "winsorized_df = df.groupby('group', group_keys=False).apply(\n",
    "    lambda x: winsorize(x, quantiles=quantiles_to_use),\n",
    "    include_groups=False # <-- This is the fix\n",
    ")\n",
    "\n",
    "# NOTE: group_keys=False is also added to prevent the group key from becoming part of the index.\n",
    "\n",
    "# Since we dropped the grouping column ('group'), we need to re-merge it or use the original index\n",
    "winsorized_df = winsorized_df.reset_index(drop=True)[['sequence']]\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"Winsorized DataFrame (First Rows):\")\n",
    "print(winsorized_df.head(11).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58459ea3-452c-4e35-92b1-d460fda21a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cc677-56b6-462d-97f5-0f0dd71bdab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4af01-f094-4a90-8c1b-bd1b0aff71f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba40bb8-d9f8-4b21-bd75-31a266c7e819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd80f27-3dac-4e5a-888c-dd7052a799fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b071a52-8ecc-4858-84dc-cb59273616ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1059c858-29c1-4725-bc8e-5817f08fafc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01d865-1faa-4add-947d-1b1e40ae8ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97b073-aec8-4e45-925e-b3aa58119226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774874c-bf16-4e43-82fe-c064c75bab93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519ab0a-89d0-4087-98c4-d4cdce698dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
